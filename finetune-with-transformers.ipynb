{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e24f4b87-c822-4d82-bba2-520aa55f50ea",
   "metadata": {},
   "source": [
    "# transformersのライブラリを利用したtfのBERT事前学習モデルのfinetuneのサンプル\n",
    "\n",
    "ポイント\n",
    "\n",
    "- transformers, datasetsなどのライブラリに頼ることで、コードが短くわかりやすい\n",
    "- transformersはtensorflowのモデルをpytorchに持ち込める\n",
    "- livedoor ニュースコーパスの文章分類をdownstream taskとした\n",
    "\n",
    "## ライブラリ\n",
    "pythonの仮想環境、パッケージはpoetryを使用しました  \n",
    "pyproject.tomlを見てもらえるとわかりますが、特にこのnotebookで使用したのは以下になるとおもいます。\n",
    "\n",
    "```\n",
    "python = \"^3.7.1\"\n",
    "jupyterlab = \"^3.1.6\"\n",
    "ipywidgets = \"^7.6.3\"\n",
    "torch = \"^1.9.0\"\n",
    "transformers = \"^4.9.2\"\n",
    "sentencepiece = \"^0.1.96\"\n",
    "datasets = \"^1.11.0\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe8db0df-f8e9-4654-b07e-50bb5874df1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93050856-7bba-4e4f-8402-cc56e5aefb3d",
   "metadata": {},
   "source": [
    "GPUが使えるかチェックしましょう↑"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ff895f-769b-4dab-b787-1a3782b3692a",
   "metadata": {},
   "source": [
    "## finetuneのためのデータのダウンロードとdataframe化\n",
    "\n",
    "./dataにライブドアニュースコーパスをダウンロードしてgzipを展開します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "634819ef-9ce2-462b-9776-34bd18da9c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "import urllib\n",
    "import tarfile\n",
    "\n",
    "url = \"https://www.rondhuit.com/download/ldcc-20140209.tar.gz\"\n",
    "download_dir = Path('./download/')\n",
    "download_dir.mkdir(exist_ok=True)\n",
    "\n",
    "local_filename, headers = urllib.request.urlretrieve(url, download_dir / \"ldcc-20140209.tar.gz\")\n",
    "extract_dir = download_dir / \"ldcc-20140209\"\n",
    "with tarfile.open(local_filename, \"r:gz\") as tar:\n",
    "    tar.extractall(extract_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41762df-2cb0-4fe5-834c-a8310ed3f6e4",
   "metadata": {},
   "source": [
    "展開したデータからpandasのDataFrameを作ります\n",
    "\n",
    "ここらへんは展開したフォルダの構造を見ながらpythonでよしなにやっていきます。\n",
    "ぐぐるとコード例もよく見つかります"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2412da2a-79e7-4fd5-a9a4-5b2bf48fcb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\"category\", \"url\", \"time\", \"title\", \"text\"])\n",
    "for txt_path in extract_dir.glob('text/*/*.txt'):\n",
    "    file_name = txt_path.name\n",
    "    category_name = txt_path.parent.name\n",
    "\n",
    "    if file_name in [\"CHANGES.txt\", \"README.txt\", \"LICENSE.txt\"]:\n",
    "        continue\n",
    "\n",
    "    text_all = txt_path.read_text()\n",
    "    text_lines = text_all.split(\"\\n\")\n",
    "    url, time, title, *article = text_lines\n",
    "    article = \"\\n\".join(article)\n",
    "\n",
    "    df.loc[file_name] = [category_name, url, time, title, article]\n",
    "\n",
    "df.reset_index(inplace=True)\n",
    "df.rename(columns={\"index\": \"filename\"}, inplace=True)\n",
    "\n",
    "\n",
    "categories = df.category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7e8ec73-681f-4fe0-bd53-80f99a5f2d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>category</th>\n",
       "      <th>url</th>\n",
       "      <th>time</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it-life-hack-6380347.txt</td>\n",
       "      <td>it-life-hack</td>\n",
       "      <td>http://news.livedoor.com/article/detail/6380347/</td>\n",
       "      <td>2012-03-18T15:00:00+0900</td>\n",
       "      <td>CPUもGPUも祭だワッショイ！GIGABYTE板祭でマザボ＆グラボのレビューアーを大募集</td>\n",
       "      <td>ソーシャルレビューコミュニティ「zigsow」（ジグソー）は、「GIGABYTE板祭 Ret...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it-life-hack-6394776.txt</td>\n",
       "      <td>it-life-hack</td>\n",
       "      <td>http://news.livedoor.com/article/detail/6394776/</td>\n",
       "      <td>2012-03-23T09:55:00+0900</td>\n",
       "      <td>新iPad時代の定番はコレだ！iPhoneとiPadを同時充電＋ステレオスピーカー内蔵スタン...</td>\n",
       "      <td>iPhoneとiPadは、どちらも使っている人も多いが、新iPadが登場したことで、この傾向...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>it-life-hack-6628356.txt</td>\n",
       "      <td>it-life-hack</td>\n",
       "      <td>http://news.livedoor.com/article/detail/6628356/</td>\n",
       "      <td>2012-06-05T17:00:00+0900</td>\n",
       "      <td>ニコニコ動画の音楽ダウンロード始まる！NicoSoundにJASRACに加えJRCの管理楽曲が対応</td>\n",
       "      <td>日本最大級の動画サービス「niconico」のコンテンツ「ニコニコ動画：Zero」から提供が...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it-life-hack-6830890.txt</td>\n",
       "      <td>it-life-hack</td>\n",
       "      <td>http://news.livedoor.com/article/detail/6830890/</td>\n",
       "      <td>2012-08-07T10:00:00+0900</td>\n",
       "      <td>購入してよかったの最高はEOS DIGITAL　ブランド総合研究所「デジタル家電イメージ調査...</td>\n",
       "      <td>株式会社ブランド総合研究所は、10のデジタル家電分野154ブランド（商品名及び企業名）を対象...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it-life-hack-6719823.txt</td>\n",
       "      <td>it-life-hack</td>\n",
       "      <td>http://news.livedoor.com/article/detail/6719823/</td>\n",
       "      <td>2012-07-03T13:00:00+0900</td>\n",
       "      <td>自分の顔で画面ロックを解除！ドコモ、GALAXY S IIにAndroid 4.0を提供</td>\n",
       "      <td>ドコモは2012年7月3日、サムスン製のスマートフォン「GALAXY S II SC-02C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   filename      category  \\\n",
       "0  it-life-hack-6380347.txt  it-life-hack   \n",
       "1  it-life-hack-6394776.txt  it-life-hack   \n",
       "2  it-life-hack-6628356.txt  it-life-hack   \n",
       "3  it-life-hack-6830890.txt  it-life-hack   \n",
       "4  it-life-hack-6719823.txt  it-life-hack   \n",
       "\n",
       "                                                url                      time  \\\n",
       "0  http://news.livedoor.com/article/detail/6380347/  2012-03-18T15:00:00+0900   \n",
       "1  http://news.livedoor.com/article/detail/6394776/  2012-03-23T09:55:00+0900   \n",
       "2  http://news.livedoor.com/article/detail/6628356/  2012-06-05T17:00:00+0900   \n",
       "3  http://news.livedoor.com/article/detail/6830890/  2012-08-07T10:00:00+0900   \n",
       "4  http://news.livedoor.com/article/detail/6719823/  2012-07-03T13:00:00+0900   \n",
       "\n",
       "                                               title  \\\n",
       "0      CPUもGPUも祭だワッショイ！GIGABYTE板祭でマザボ＆グラボのレビューアーを大募集   \n",
       "1  新iPad時代の定番はコレだ！iPhoneとiPadを同時充電＋ステレオスピーカー内蔵スタン...   \n",
       "2  ニコニコ動画の音楽ダウンロード始まる！NicoSoundにJASRACに加えJRCの管理楽曲が対応   \n",
       "3  購入してよかったの最高はEOS DIGITAL　ブランド総合研究所「デジタル家電イメージ調査...   \n",
       "4       自分の顔で画面ロックを解除！ドコモ、GALAXY S IIにAndroid 4.0を提供   \n",
       "\n",
       "                                                text  \n",
       "0  ソーシャルレビューコミュニティ「zigsow」（ジグソー）は、「GIGABYTE板祭 Ret...  \n",
       "1  iPhoneとiPadは、どちらも使っている人も多いが、新iPadが登場したことで、この傾向...  \n",
       "2  日本最大級の動画サービス「niconico」のコンテンツ「ニコニコ動画：Zero」から提供が...  \n",
       "3  株式会社ブランド総合研究所は、10のデジタル家電分野154ブランド（商品名及び企業名）を対象...  \n",
       "4  ドコモは2012年7月3日、サムスン製のスマートフォン「GALAXY S II SC-02C...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bfeec43-1e39-4363-b6b6-6daca363eed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['it-life-hack', 'movie-enter', 'livedoor-homme', 'smax',\n",
       "       'topic-news', 'kaden-channel', 'sports-watch', 'dokujo-tsushin',\n",
       "       'peachy'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a836257d-70ae-43a8-9b01-e60583d7d2db",
   "metadata": {},
   "source": [
    "## 事前学習モデルの準備\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4a2490-efef-483e-b409-e9c706778e78",
   "metadata": {},
   "source": [
    "事前学習済みデータをダウンロードします\n",
    "\n",
    "google driveからのダウンロードはかなりpythonコード化しにくいので手作業してください\n",
    "\n",
    "https://github.com/yoheikikuta/bert-japanese#pretrained-models\n",
    "\n",
    "ここから以下をダウンロードします\n",
    "[![Image from Gyazo](https://i.gyazo.com/2c1a9f74194a20801197ed686601cb82.png)](https://gyazo.com/2c1a9f74194a20801197ed686601cb82)\n",
    "\n",
    "真ん中のbz2は事前学習のために使ったwikipediaのページのデータなのでfinetuneにはいらないはずです。\n",
    "\n",
    "wikipediaのアーカイブは古いのは消えていくので再現性の担保のために保存していると思われます\n",
    "\n",
    "google driveからダウンロードしたデータを任意のフォルダに置いて、model_dirの変数にフォルダのpathを書いてください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e13c1015-d0db-44ce-880d-488f57bde5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_dir = '' # ここにダウンロードしたフォルダを書いてください\n",
    "model_dir = '/mnt/d/yoheikikuta-bert-japanese/'\n",
    "\n",
    "base_ckpt = 'model.ckpt-1400000'  # 拡張子は含めない"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed5372e-3eac-4f49-971c-71aaac14f83f",
   "metadata": {},
   "source": [
    "### modelのconfigの用意\n",
    "\n",
    "vocab_sizeを指定する必要があるが、これは、トークンをidに対応させるためのtableのサイズのことである\n",
    "\n",
    "これはwiki-ja.vocabにtsvとして入っているので、この行数がvocab_sizeとなる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "966080fb-6803-4e44-9f4a-9ec002f8dca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000\n"
     ]
    }
   ],
   "source": [
    "! cat {model_dir}wiki-ja.vocab | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cddd38ed-e5dc-47c6-a0e1-5b0c785c8a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unk>\t0\n",
      "<s>\t0\n",
      "</s>\t0\n",
      "[PAD]\t0\n",
      "[CLS]\t0\n",
      "[SEP]\t0\n",
      "[MASK]\t0\n",
      "、\t-3.00936\n",
      "。\t-3.28261\n",
      "▁\t-3.52378\n",
      "の\t-3.65896\n",
      "は\t-4.00699\n",
      "が\t-4.361\n",
      "・\t-4.43092\n",
      ")\t-4.47007\n",
      "(\t-4.54356\n",
      "年\t-4.57164\n",
      "に\t-4.67272\n",
      "を\t-4.69082\n",
      "で\t-4.87051\n",
      "cat: write error: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "! cat {model_dir}wiki-ja.vocab | head -n 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdf35792-6705-44d0-9955-10d5bb3ee2f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import BertConfig, BertForPreTraining, BertForSequenceClassification\n",
    "\n",
    "vocab_size = 32000\n",
    "bertconfig = BertConfig.from_pretrained('bert-base-uncased',\n",
    "                                        num_labels=len(categories),\n",
    "                                        output_attentions = False,\n",
    "                                        output_hidden_states = False,\n",
    "                                       )\n",
    "bertconfig.vocab_size = vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476066c0-d404-49c1-9e1f-a1a4708baf48",
   "metadata": {},
   "source": [
    "### モデルの用意と読み込み\n",
    "\n",
    "tfの重みを読み込んで、save_pretrainedでストレージに保存してから、BertForSequenceClassificationで読み込む\n",
    "\n",
    "こうすることで、手軽にtfの重みを使ってtransformersのモデルでfinetuneができるという寸法です\n",
    "\n",
    "当然、sequence classificationにはpretrainingのモデルよりもpooler layer(transformer stackの後ろの層)があって、そこが存在しなくて読み込めないのでwarnされます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d925d65c-174e-48fc-b08b-384dad626def",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./tmp were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./tmp and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# BERTモデルの\"ガワ\"の用意 (全パラメーターはランダムに初期化されている)\n",
    "pretrained = BertForPreTraining(bertconfig)\n",
    "# TensorFlowモデルの重み行列を読み込む (数分程度かかる場合がある)\n",
    "pretrained.load_tf_weights(bertconfig, model_dir + base_ckpt)\n",
    "\n",
    "tmp_dir = './tmp'\n",
    "pretrained.save_pretrained(tmp_dir)\n",
    "model = BertForSequenceClassification.from_pretrained(tmp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18596f67-b468-4861-a571-71dc15e918b2",
   "metadata": {},
   "source": [
    "## データセットの変換\n",
    "\n",
    "livedoorコーパスのDataFrameをモデルに流すためのデータセットに変換します\n",
    "\n",
    "huggingfaceが出している、datasetsというライブラリを使います。\n",
    "\n",
    "https://huggingface.co/docs/datasets/index.html\n",
    "\n",
    "transformersもdatasetsも同じhuggingfaceが出しているので、値を流すのが楽です"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247d0624-c5c1-41d8-8e5f-ea81d2e692e9",
   "metadata": {},
   "source": [
    "まずはcategoryのカラムを数値idにして、labelsというカラムにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ad2f4b4-6190-4bb2-a78e-24a769bd598c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it-life-hack</td>\n",
       "      <td>ソーシャルレビューコミュニティ「zigsow」（ジグソー）は、「GIGABYTE板祭 Ret...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it-life-hack</td>\n",
       "      <td>iPhoneとiPadは、どちらも使っている人も多いが、新iPadが登場したことで、この傾向...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>it-life-hack</td>\n",
       "      <td>日本最大級の動画サービス「niconico」のコンテンツ「ニコニコ動画：Zero」から提供が...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it-life-hack</td>\n",
       "      <td>株式会社ブランド総合研究所は、10のデジタル家電分野154ブランド（商品名及び企業名）を対象...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it-life-hack</td>\n",
       "      <td>ドコモは2012年7月3日、サムスン製のスマートフォン「GALAXY S II SC-02C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       category                                               text\n",
       "0  it-life-hack  ソーシャルレビューコミュニティ「zigsow」（ジグソー）は、「GIGABYTE板祭 Ret...\n",
       "1  it-life-hack  iPhoneとiPadは、どちらも使っている人も多いが、新iPadが登場したことで、この傾向...\n",
       "2  it-life-hack  日本最大級の動画サービス「niconico」のコンテンツ「ニコニコ動画：Zero」から提供が...\n",
       "3  it-life-hack  株式会社ブランド総合研究所は、10のデジタル家電分野154ブランド（商品名及び企業名）を対象...\n",
       "4  it-life-hack  ドコモは2012年7月3日、サムスン製のスマートフォン「GALAXY S II SC-02C..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['category', 'text']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cd220b4-8e44-4121-993f-27d43ceb5892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it-life-hack</td>\n",
       "      <td>1</td>\n",
       "      <td>ソーシャルレビューコミュニティ「zigsow」（ジグソー）は、「GIGABYTE板祭 Ret...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it-life-hack</td>\n",
       "      <td>1</td>\n",
       "      <td>iPhoneとiPadは、どちらも使っている人も多いが、新iPadが登場したことで、この傾向...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>it-life-hack</td>\n",
       "      <td>1</td>\n",
       "      <td>日本最大級の動画サービス「niconico」のコンテンツ「ニコニコ動画：Zero」から提供が...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it-life-hack</td>\n",
       "      <td>1</td>\n",
       "      <td>株式会社ブランド総合研究所は、10のデジタル家電分野154ブランド（商品名及び企業名）を対象...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it-life-hack</td>\n",
       "      <td>1</td>\n",
       "      <td>ドコモは2012年7月3日、サムスン製のスマートフォン「GALAXY S II SC-02C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       category  labels                                               text\n",
       "0  it-life-hack       1  ソーシャルレビューコミュニティ「zigsow」（ジグソー）は、「GIGABYTE板祭 Ret...\n",
       "1  it-life-hack       1  iPhoneとiPadは、どちらも使っている人も多いが、新iPadが登場したことで、この傾向...\n",
       "2  it-life-hack       1  日本最大級の動画サービス「niconico」のコンテンツ「ニコニコ動画：Zero」から提供が...\n",
       "3  it-life-hack       1  株式会社ブランド総合研究所は、10のデジタル家電分野154ブランド（商品名及び企業名）を対象...\n",
       "4  it-life-hack       1  ドコモは2012年7月3日、サムスン製のスマートフォン「GALAXY S II SC-02C..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['labels'] = df['category'].astype('category').cat.codes\n",
    "df[['category','labels', 'text']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1d3bf5-45b2-4459-9e98-b0208a9348a6",
   "metadata": {},
   "source": [
    "text,とlabelsのカラムからdatasetを作ります"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3f62152-ea70-4bc5-b4d8-1d187340c8bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'labels'],\n",
       "        num_rows: 5525\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'labels'],\n",
       "        num_rows: 1842\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "ds = Dataset.from_pandas(df[['text', 'labels']])\n",
    "dataset = ds.train_test_split()\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f52ee3-4486-475c-8885-37126e092888",
   "metadata": {},
   "source": [
    "## tokenizerの用意\n",
    "tokenizerは事前学習に用いたものと同じでなければいけません。\n",
    "\n",
    "今回はyoheikikuta氏のモデルなので、Sentencepieceを使います。\n",
    "\n",
    "transformersのモデルの中にもsentencepieceを使ったものがあるので、このtokenizerを流用します。  \n",
    "transformersのドキュメントとソースを見ながら,Albertのtokenizerを利用することにしました。\n",
    "\n",
    "https://huggingface.co/transformers/_modules/transformers/models/albert/tokenization_albert.html#AlbertTokenizer\n",
    "\n",
    "Albert自体とは何も関係がありません。\n",
    "\n",
    "先程google dirveからダウンロードしたものの中にwiki-ja.modelがあるので、このpathを渡します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40993867-649a-49bf-85fe-e2c4d1f2c440",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_SPM = 'wiki-ja.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8328eccb-c09a-45ed-b7ab-bb6c9d9e85ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AlbertTokenizer\n",
    "tokenizer = AlbertTokenizer(model_dir + BASE_SPM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b97399-e630-4482-8ff3-38528873316f",
   "metadata": {},
   "source": [
    "datasetにtokenizeをかけます。  \n",
    "これはmap関数を使うと便利で、batch化もoptionで指定するとできます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "803a54eb-6c4e-481f-8622-053fa148c628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "179823d324c44b2eac99cc61c79c0e62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5217254e2d34445082cc8cdb41ffdbae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_length = bertconfig.max_position_embeddings\n",
    "\n",
    "def tokenize(examples):\n",
    "    input_ids = tokenizer(examples[\"text\"], max_length=max_length, padding=\"max_length\",truncation=True,).input_ids\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"labels\": examples['labels']\n",
    "    }\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, batched=True, remove_columns=['text'])\n",
    "tokenized_dataset.set_format(type='torch', columns=['input_ids', 'labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3964dad9-c830-44b2-92c9-e38758236c5b",
   "metadata": {},
   "source": [
    "## finetuneの実行\n",
    "\n",
    "transformersが提供してるTranierクラスを使ってfinetuneを行います"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28def65c-0717-4e73-9372-318978698624",
   "metadata": {},
   "source": [
    "動作確認のため、epochs数は少なめで、他の数値も適当です"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e10c9780-cdd4-4c71-a445-4d909eb5d44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "\n",
    "# Trainerのパラメータの準備\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # 出力フォルダ\n",
    "    num_train_epochs=2,              # エポック数\n",
    "    per_device_train_batch_size=4,  # 訓練のバッチサイズ\n",
    "    per_device_eval_batch_size=4,   # 評価のバッチサイズ\n",
    "    warmup_steps=500,                # 学習率スケジューラのウォームアップステップ数\n",
    "    weight_decay=0.01,               # 重み減衰の強さ\n",
    "    logging_dir='./logs',            # ログ保存フォルダ\n",
    "    eval_accumulation_steps=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b08fe75-cb86-4527-8650-9da0c5bdfc62",
   "metadata": {},
   "source": [
    "## 指標の用意\n",
    "\n",
    "trainした結果の精度などを評価する際に使う指標を選びます。\n",
    "\n",
    "huggingface/datasetsライブラリの中にお手軽に指標を用意するload_metricがあるのでこれを使います。\n",
    "\n",
    "compute_metrics 関数を定義してTrainerにわたすことでtrainer.evaluate()で、eval_datasetのデータから指標を計算してくれます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "175407fb-fa0a-4884-bde4-7374f4bff347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "f1 = load_metric(\"f1\")\n",
    "acc = load_metric(\"accuracy\")\n",
    "precision = load_metric(\"precision\")\n",
    "recall = load_metric(\"recall\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    params = dict(predictions=predictions, references=labels,)\n",
    "    return { \n",
    "        **acc.compute(**params),\n",
    "        **f1.compute(**params, average=\"weighted\"),\n",
    "        **precision.compute(**params, average=\"weighted\"),\n",
    "        **recall.compute(**params, average=\"weighted\"),\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83e8aa33-0cd2-4bb2-a9aa-463dab0ad687",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "# Trainerの準備\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],     # 訓練データセット\n",
    "    eval_dataset=tokenized_dataset['test'],        # 評価データセット\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fe9b02-1144-4025-88f8-fbf69821311e",
   "metadata": {},
   "source": [
    "今回のデータ量と設定やPCの環境にもよりますが、私の手元だとfinetuneに20minくらいかかりました"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e97b953-1dd3-4c95-9aad-cf40b9303e57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 5525\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2764\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2764' max='2764' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2764/2764 19:58, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.125600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.510600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.209500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.171900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results/checkpoint-500\n",
      "Configuration saved in ./results/checkpoint-500/config.json\n",
      "Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n",
      "Saving model checkpoint to ./results/checkpoint-1000\n",
      "Configuration saved in ./results/checkpoint-1000/config.json\n",
      "Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n",
      "Saving model checkpoint to ./results/checkpoint-1500\n",
      "Configuration saved in ./results/checkpoint-1500/config.json\n",
      "Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n",
      "Saving model checkpoint to ./results/checkpoint-2000\n",
      "Configuration saved in ./results/checkpoint-2000/config.json\n",
      "Model weights saved in ./results/checkpoint-2000/pytorch_model.bin\n",
      "Saving model checkpoint to ./results/checkpoint-2500\n",
      "Configuration saved in ./results/checkpoint-2500/config.json\n",
      "Model weights saved in ./results/checkpoint-2500/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2764, training_loss=0.4536512129213634, metrics={'train_runtime': 1199.4706, 'train_samples_per_second': 9.212, 'train_steps_per_second': 2.304, 'total_flos': 2907559890892800.0, 'train_loss': 0.4536512129213634, 'epoch': 2.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d9e10c7-3630-45b3-8c56-420357982d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1842\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='461' max='461' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [461/461 00:42]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.30360835790634155,\n",
       " 'eval_accuracy': 0.9375678610206297,\n",
       " 'eval_f1': 0.9371333992019317,\n",
       " 'eval_precision': 0.9377411727515823,\n",
       " 'eval_recall': 0.9375678610206297,\n",
       " 'eval_runtime': 42.5026,\n",
       " 'eval_samples_per_second': 43.338,\n",
       " 'eval_steps_per_second': 10.846,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52dd1479-7bdb-4659-8434-f88ec61dc443",
   "metadata": {},
   "source": [
    "すくないepoch数でも精度が93%出ていることが確認できました"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7d953f-463e-42cf-947a-8211dde47922",
   "metadata": {},
   "source": [
    "## 参考文献\n",
    "\n",
    "https://github.com/miyamonz/bert-japanese-finetune-example\n",
    "\n",
    "このnotebookの前進にあたる素振り。DatasetとかTrainerを使ってない文コードが長いが、sentencepieceの書き方とか、今回AlbertTokenizerで楽をした部分の中身はこっちのほうがわかりやすい\n",
    "\n",
    "学習ループはpytorchで手書きしてるが、なにか抜けてる箇所があるかもしれない。\n",
    "transformersに頼ったほうがその点安心なのでこのnotebookを作った\n",
    "\n",
    "https://radiology-nlp.hatenablog.com/entry/2020/01/18/013039\n",
    "\n",
    "tfの重みをtransformersで読み込んでるあたり。ただしこのnotebookで示した方法のほうがシンプルでおすすめです\n",
    "\n",
    "https://www.ogis-ri.co.jp/otc/hiroba/technical/similar-document-search/part14.html\n",
    "\n",
    "別モデルですが、transformersのTrainerクラスの使い方などを参考にしました"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
